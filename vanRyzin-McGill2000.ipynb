{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook replicates McGill-van Ryzin 2000 Management Science Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test problem scenarios: four classes with different fares and demand statistics\n",
    "n_class = 4\n",
    "fare = np.array([1050, 950, 699, 520])\n",
    "mean = np.array([17.3, 45.1, 39.6, 34.0])\n",
    "std = np.array([5.8, 15.0, 13.2, 11.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_cumsum = np.cumsum(mean)\n",
    "std_cumsum = np.sqrt(np.cumsum(std**2))\n",
    "totalrev = fare * mean\n",
    "totalrev_cumsum = np.cumsum(totalrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 17.3,  62.4, 102. , 136. ]),\n",
       " array([ 5.8       , 16.08228839, 20.80576843, 23.67635952]),\n",
       " array([18165. , 42845. , 27680.4, 17680. ]),\n",
       " array([ 18165. ,  61010. ,  88690.4, 106370.4]))"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_cumsum, std_cumsum, totalrev, totalrev_cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute weighted average revenue\n",
    "avgrev_weighted = totalrev_cumsum / mean_cumsum\n",
    "# Probability of demand being higher than the protection level\n",
    "prob_emsr = np.array([fare[i+1] / avgrev_weighted[i] for i in range(n_class - 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1050.        ,  977.72435897,  869.51372549,  782.13529412]),\n",
       " array([0.9047619 , 0.71492542, 0.59803541]))"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgrev_weighted, prob_emsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMSR-b protection levels\n",
    "theta_emsr = st.norm.ppf(1 - prob_emsr, mean_cumsum[:-1], std_cumsum[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.70680404, 53.26796455, 96.83465043])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_emsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate optimal protection level based on stochastic approximation (SA)\n",
    "ratio = np.array([fare[i] / fare[0] for i in range(1, n_class)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to find optimal protection levels for SA algorithm, we use\n",
    "# monte carlo integration specified in McGill-van Ryzin(2004) book\n",
    "# Page 43\n",
    "size = 100000\n",
    "# Normal dist\n",
    "demand = np.array([[np.random.normal(mean[i], std[i], 1) for i in range(n_class)] for k in range(size)])\n",
    "demand = demand.reshape(size, n_class)\n",
    "# Lognormal dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.87242231, 35.73927795, 33.48018955, 18.9461562 ],\n",
       "       [16.60951384, 56.2724781 , 56.73055224, 38.7196455 ],\n",
       "       [13.58374079, 45.74754432, 41.47811538, 43.76904266],\n",
       "       [19.10569749, 62.06611198, 31.3018971 , 31.76259796],\n",
       "       [11.27098619, 49.87114527, 52.02159849, 34.49059692],\n",
       "       [14.76778921, 31.0124776 , 47.63076598, 38.7709801 ],\n",
       "       [22.77027774, 28.71721543, 28.82716349, 20.1136273 ],\n",
       "       [20.53327641, 57.68961445, 72.60744561, 36.19261827],\n",
       "       [17.82351009, 25.13258846, 29.19109205, 58.71143747],\n",
       "       [ 9.1164696 , 38.07574916, 44.38308885, 44.75031249]])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand[:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 15.87242231,  51.61170026,  85.09188981, 104.03804601],\n",
       "       [ 16.60951384,  72.88199194, 129.61254417, 168.33218967],\n",
       "       [ 13.58374079,  59.33128511, 100.80940049, 144.57844315],\n",
       "       [ 19.10569749,  81.17180947, 112.47370657, 144.23630453],\n",
       "       [ 11.27098619,  61.14213146, 113.16372995, 147.65432687],\n",
       "       [ 14.76778921,  45.78026681,  93.41103279, 132.1820129 ],\n",
       "       [ 22.77027774,  51.48749317,  80.31465666, 100.42828396],\n",
       "       [ 20.53327641,  78.22289086, 150.83033647, 187.02295475],\n",
       "       [ 17.82351009,  42.95609855,  72.1471906 , 130.85862806],\n",
       "       [  9.1164696 ,  47.19221876,  91.57530761, 136.3256201 ]])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute random demand partial sums\n",
    "demand_cumsum = np.array([np.cumsum(demand[i]) for i in range(size)])\n",
    "demand_cumsum[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_norm = []\n",
    "cumsum_copy = demand_cumsum.copy()\n",
    "for j in range(n_class - 1):\n",
    "    # Step 1\n",
    "    cumsum_copy_ordered = np.sort(cumsum_copy[:, j])\n",
    "    # Step 2\n",
    "    threshold = int(np.floor((fare[j+1] / fare[j]) * len(cumsum_copy_ordered)))\n",
    "    # An error in the initial algorithm. After calculation l*, there should\n",
    "    # one more calculation before finding y_j, which is the index used to calculate\n",
    "    # y_j should be |k|-l*, not l* itself.\n",
    "    threshold = len(cumsum_copy_ordered) - threshold\n",
    "    theta = 0.5 * (cumsum_copy_ordered[threshold-1] + cumsum_copy_ordered[threshold])\n",
    "    # Step 3\n",
    "    index = np.where(cumsum_copy[:, j] > theta)\n",
    "    # In step 3, we only keep the updated values we use for next iteration\n",
    "    cumsum_copy = cumsum_copy[index]\n",
    "    theta_norm.append(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.751898765608983, 53.59980258296807, 98.28777202392007]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_norm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
